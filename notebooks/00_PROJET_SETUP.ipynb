{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SECTION 1 : CONFIGURATION ET IMPORTS\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.10.1' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NumPy version: 2.4.1\n",
            " Pandas version: 3.0.0\n",
            " Matplotlib version: 3.10.8\n",
            " Seaborn version: 0.13.2\n"
          ]
        }
      ],
      "source": [
        "# standars \n",
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "#scientifique \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(f\" NumPy version: {np.__version__}\")\n",
        "print(f\" Pandas version: {pd.__version__}\")\n",
        "\n",
        "\n",
        "# traitement d'images\n",
        "from PIL import Image\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(f\" PIL  importé\")\n",
        "    print(f\" OpenCV version: {cv2.__version__}\")\n",
        "except ImportError:\n",
        "   \n",
        "    cv2 = None\n",
        "\n",
        "\n",
        "#visualisation \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(f\" Matplotlib version: {matplotlib.__version__}\")\n",
        "print(f\" Seaborn version: {sns.__version__}\")\n",
        "\n",
        "\n",
        "#Machine learning \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "#utilitaires \n",
        "from tqdm import tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Chargement "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration chargée a \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "CONFIG_PATH = Path(r\"A:\\Mes documents\\CNN\\config.yaml\")\n",
        "\n",
        "if not CONFIG_PATH.exists():\n",
        "    raise FileNotFoundError(f\" Fichier config.yaml introuvable: {CONFIG_PATH}\")\n",
        "\n",
        "with open(CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\" Configuration chargée a \")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Définition des constantes globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BASE_DIR           : A:\\Mes documents\\CNN\n",
            "RAW_DATA_PATH      : A:\\Mes documents\\CNN\\data\\raw\\simpsons_dataset\n",
            "TEST_DATA_PATH     : A:\\Mes documents\\CNN\\data\\raw\\kaggle_simpson_testset\n",
            "BALANCED_DATA_PATH : A:\\Mes documents\\CNN\\data\\balanced\\simpsons_balanced\n",
            "OUTPUTS_DIR        : A:\\Mes documents\\CNN\\outputs\n",
            "FIGURES_DIR        : A:\\Mes documents\\CNN\\outputs\\figures\n",
            "REPORTS_DIR        : A:\\Mes documents\\CNN\\outputs\\reports\n",
            "\n",
            "N_CLASSES          : 13\n",
            "IMAGES_PER_CLASS   : 850\n",
            "IMAGE_SIZE         : (224, 224)\n",
            "BATCH_SIZE         : 32\n",
            "RANDOM_SEED        : 42\n",
            "\n",
            "CLASSES:\n",
            "   1. abraham_grampa_simpson\n",
            "   2. bart_simpson\n",
            "   3. charles_montgomery_burns\n",
            "   4. chief_wiggum\n",
            "   5. homer_simpson\n",
            "   6. krusty_the_clown\n",
            "   7. lisa_simpson\n",
            "   8. marge_simpson\n",
            "   9. milhouse_van_houten\n",
            "  10. moe_szyslak\n",
            "  11. ned_flanders\n",
            "  12. principal_skinner\n",
            "  13. sideshow_bob\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Chemins principaux\n",
        "BASE_DIR = Path(config['paths']['base_dir'])\n",
        "RAW_DATA_PATH = BASE_DIR / config['paths']['data']['raw']\n",
        "TEST_DATA_PATH = BASE_DIR / config['paths']['data']['test_raw']\n",
        "BALANCED_DATA_PATH = BASE_DIR / config['paths']['data']['balanced']\n",
        "PROCESSED_TRAIN_PATH = BASE_DIR / config['paths']['data']['processed']['train']\n",
        "PROCESSED_VAL_PATH = BASE_DIR / config['paths']['data']['processed']['validation']\n",
        "PROCESSED_TEST_PATH = BASE_DIR / config['paths']['data']['processed']['test']\n",
        "\n",
        "# Chemins pour les modèles\n",
        "MODELS_DIR = BASE_DIR / config['paths']['models']\n",
        "\n",
        "# Chemins pour outputs \n",
        "if isinstance(config['paths']['outputs'], dict):\n",
        "    # Ancien format (dict)\n",
        "    OUTPUTS_DIR = BASE_DIR / 'outputs'\n",
        "    FIGURES_DIR = BASE_DIR / config['paths']['outputs']['figures']\n",
        "    REPORTS_DIR = BASE_DIR / config['paths']['outputs']['reports']\n",
        "    PREDICTIONS_DIR = BASE_DIR / config['paths']['outputs']['predictions']\n",
        "else:\n",
        "    # Nouveau format (string)\n",
        "    OUTPUTS_DIR = BASE_DIR / config['paths']['outputs']\n",
        "    FIGURES_DIR = OUTPUTS_DIR / 'figures'\n",
        "    REPORTS_DIR = OUTPUTS_DIR / 'reports'\n",
        "    PREDICTIONS_DIR = OUTPUTS_DIR / 'predictions'\n",
        "\n",
        "\n",
        "# Paramètres des données\n",
        "N_CLASSES = config['data']['n_classes']\n",
        "IMAGES_PER_CLASS = config['data']['images_per_class']\n",
        "TRAIN_VAL_SPLIT = config['data']['train_val_split']\n",
        "IMAGE_SIZE = tuple(config['data']['image_size'])\n",
        "BATCH_SIZE = config['data']['batch_size']\n",
        "RANDOM_SEED = config['data']['random_seed']\n",
        "STRATIFIED_SAMPLING = config['data']['stratified_sampling']\n",
        "\n",
        "# Classes \n",
        "CLASSES = config['classes']\n",
        "\n",
        "# Fixer la graine aléatoire pour la reproductibilité\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# RESUMMME\n",
        "\n",
        "print(f\"BASE_DIR           : {BASE_DIR}\")\n",
        "print(f\"RAW_DATA_PATH      : {RAW_DATA_PATH}\")\n",
        "print(f\"TEST_DATA_PATH     : {TEST_DATA_PATH}\")\n",
        "print(f\"BALANCED_DATA_PATH : {BALANCED_DATA_PATH}\")\n",
        "print(f\"OUTPUTS_DIR        : {OUTPUTS_DIR}\")\n",
        "print(f\"FIGURES_DIR        : {FIGURES_DIR}\")\n",
        "print(f\"REPORTS_DIR        : {REPORTS_DIR}\")\n",
        "print()\n",
        "print(f\"N_CLASSES          : {N_CLASSES}\")\n",
        "print(f\"IMAGES_PER_CLASS   : {IMAGES_PER_CLASS}\")\n",
        "print(f\"IMAGE_SIZE         : {IMAGE_SIZE}\")\n",
        "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
        "print(f\"RANDOM_SEED        : {RANDOM_SEED}\")\n",
        "print()\n",
        "print(\"CLASSES:\")\n",
        "for i, classe in enumerate(CLASSES, 1):\n",
        "    print(f\"  {i:2d}. {classe}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SECTION 2 : ACQUISITION ET VÉRIFICATION DES DONNÉES\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Fonctions utilitaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images_per_class(data_path, classes):\n",
        "    \n",
        "    counts = {}\n",
        "    \n",
        "    for class_name in classes:\n",
        "        class_path = data_path / class_name\n",
        "        \n",
        "        if class_path.exists():\n",
        "            # Utiliser un set pour éviter les doublons\n",
        "            images = set()\n",
        "            \n",
        "            # Ajouter toutes les extensions \n",
        "            images.update(class_path.glob(\"*.jpg\"))\n",
        "            images.update(class_path.glob(\"*.jpeg\"))\n",
        "            images.update(class_path.glob(\"*.png\"))\n",
        "            \n",
        "            counts[class_name] = len(images)\n",
        "        else:\n",
        "            print(f\"  Dossier manquant: {class_path}\")\n",
        "            counts[class_name] = 0\n",
        "    \n",
        "    return counts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Pour verifier si une image peut être ouverte sans erreur\n",
        "\n",
        "def verify_image(image_path):\n",
        "   \n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "        \n",
        "\n",
        "\n",
        "#Recup les dimensions d'une image\n",
        "def get_image_dimensions(image_path):\n",
        "    \n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            return img.size  # (width, height)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "# Calculer la luminosité moyenne d'une image\n",
        "def get_image_brightness(image_path):\n",
        "   \n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            # Convertir en niveaux de gris\n",
        "            img_gray = img.convert('L')\n",
        "            # Calculer la moyenne\n",
        "            return np.mean(np.array(img_gray))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Comptage des images par classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  abraham_grampa_simpson              :   913 images\n",
            "  bart_simpson                        :  1342 images\n",
            "  charles_montgomery_burns            :  1193 images\n",
            "  chief_wiggum                        :   986 images\n",
            "  homer_simpson                       :  2246 images\n",
            "  krusty_the_clown                    :  1206 images\n",
            "  lisa_simpson                        :  1354 images\n",
            "  marge_simpson                       :  1291 images\n",
            "  milhouse_van_houten                 :  1079 images\n",
            "  moe_szyslak                         :  1452 images\n",
            "  ned_flanders                        :  1454 images\n",
            "  principal_skinner                   :  1194 images\n",
            "  sideshow_bob                        :   877 images\n",
            "------------------------------------------------------------\n",
            "  TOTAL                               : 16587 images\n",
            "\n",
            "Test set (kaggle_simpson_testset):\n",
            "\n",
            "  Nombre d'images de test :   641 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "image_counts = count_images_per_class(RAW_DATA_PATH, CLASSES)\n",
        "\n",
        "# Affichage des résultats\n",
        "total_images = 0\n",
        "for class_name, count in image_counts.items():\n",
        "    print(f\"  {class_name:35s} : {count:5d} images\")\n",
        "    total_images += count\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"  {'TOTAL':35s} : {total_images:5d} images\")\n",
        "print()\n",
        "\n",
        "# Compter les images de test\n",
        "print(\"Test set (kaggle_simpson_testset):\")\n",
        "print()\n",
        "if TEST_DATA_PATH.exists():\n",
        "    test_images = (list(TEST_DATA_PATH.glob(\"*.jpg\")) + \n",
        "                   list(TEST_DATA_PATH.glob(\"*.jpeg\")) + \n",
        "                   list(TEST_DATA_PATH.glob(\"*.png\")))\n",
        "    print(f\"  Nombre d'images de test : {len(test_images):5d} images\")\n",
        "else:\n",
        "    print(\"    Dossier de test pas  trouvé\")\n",
        "    test_images = []\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Détection des images corrompues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Vérification des classes: 100%|██████████| 13/13 [03:26<00:00, 15.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Aucune image corrompue détectée \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "corrupted_images = []\n",
        "\n",
        "for class_name in tqdm(CLASSES, desc=\"Vérification des classes\"):\n",
        "    class_path = RAW_DATA_PATH / class_name\n",
        "    \n",
        "    if class_path.exists():\n",
        "        images = (list(class_path.glob(\"*.jpg\")) + \n",
        "                 list(class_path.glob(\"*.jpeg\")) + \n",
        "                 list(class_path.glob(\"*.png\")))\n",
        "        \n",
        "        for img_path in images:\n",
        "            if not verify_image(img_path):\n",
        "                corrupted_images.append(str(img_path))\n",
        "\n",
        "print()\n",
        "if len(corrupted_images) == 0:\n",
        "    print(\" Aucune image corrompue détectée \")\n",
        "else:\n",
        "    print(f\"  {len(corrupted_images)} image(s) corrompue(s) détectée(s)\")\n",
        "    for img in corrupted_images[:5]:\n",
        "        print(f\"     - {img}\")\n",
        "    if len(corrupted_images) > 5:\n",
        "        print(f\"     ... et {len(corrupted_images) - 5} autre(s)\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Statistiques globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre total d'images    : 16587\n",
            "Nombre de classes        : 13\n",
            "\n",
            "Distribution par classe:\n",
            "  - Minimum              : 877 images (sideshow_bob)\n",
            "  - Maximum              : 2246 images (homer_simpson)\n",
            "  - Moyenne              : 1275.9 images\n",
            "  - Médiane              : 1206.0 images\n",
            "  - Écart-type           : 333.6 images\n",
            "\n",
            "Ratio max/min            : 2.56x\n",
            "Images corrompues        : 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "counts_values = list(image_counts.values())\n",
        "min_images = min(counts_values)\n",
        "max_images = max(counts_values)\n",
        "mean_images = np.mean(counts_values)\n",
        "median_images = np.median(counts_values)\n",
        "std_images = np.std(counts_values)\n",
        "\n",
        "print(f\"Nombre total d'images    : {sum(counts_values)}\")\n",
        "print(f\"Nombre de classes        : {len(CLASSES)}\")\n",
        "print()\n",
        "print(\"Distribution par classe:\")\n",
        "print(f\"  - Minimum              : {min_images} images ({[k for k, v in image_counts.items() if v == min_images][0]})\")\n",
        "print(f\"  - Maximum              : {max_images} images ({[k for k, v in image_counts.items() if v == max_images][0]})\")\n",
        "print(f\"  - Moyenne              : {mean_images:.1f} images\")\n",
        "print(f\"  - Médiane              : {median_images:.1f} images\")\n",
        "print(f\"  - Écart-type           : {std_images:.1f} images\")\n",
        "print()\n",
        "print(f\"Ratio max/min            : {max_images/min_images:.2f}x\")\n",
        "print(f\"Images corrompues        : {len(corrupted_images)}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Sauvegarde "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Rapport sauvegardé dans : A:\\Mes documents\\CNN\\outputs\\reports\\data_report.csv\n"
          ]
        }
      ],
      "source": [
        "data_report = pd.DataFrame([\n",
        "    {'Classe': classe, 'Nombre_Images': count}\n",
        "    for classe, count in image_counts.items()\n",
        "])\n",
        "data_report.loc[len(data_report)] = ['TOTAL', sum(counts_values)]\n",
        "\n",
        "report_path = REPORTS_DIR / 'data_report.csv'\n",
        "data_report.to_csv(report_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\" Rapport sauvegardé dans : {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SECTION 3 : ANALYSE EXPLORATOIRE DES DONNÉES (EDA)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Créer le dossier pour les figures EDA\n",
        "EDA_FIGURES_DIR = FIGURES_DIR / 'eda'\n",
        "EDA_FIGURES_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Visualisation de la distribution des classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Graphique sauvegardé dans: A:\\Mes documents\\CNN\\outputs\\figures\\eda\\01_distribution_classes.png\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "classes_names = list(image_counts.keys())\n",
        "classes_counts = list(image_counts.values())\n",
        "\n",
        "bars = plt.bar(range(len(classes_names)), classes_counts, \n",
        "               color='steelblue', alpha=0.8, edgecolor='navy', linewidth=1.5)\n",
        "\n",
        "# Ajout de valeurs\n",
        "for bar, value in zip(bars, classes_counts):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 30,\n",
        "            f'{value}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Ligne de moyenne\n",
        "plt.axhline(y=mean_images, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Moyenne: {mean_images:.0f} images', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Classes (Personnages)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Nombre d\\'images', fontsize=14, fontweight='bold')\n",
        "plt.title('Distribution des Images par Classe (Dataset pas encore exploité)', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xticks(range(len(classes_names)), classes_names, rotation=45, ha='right', fontsize=10)\n",
        "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "plt.legend(fontsize=12)\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = EDA_FIGURES_DIR / '01_distribution_classes.png'\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Graphique sauvegardé dans: {save_path}\")\n",
        "plt.close()\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.  Analyse des dimensions des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyse des dimensions: 100%|██████████| 13/13 [00:00<00:00, 34.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyse effectuée sur 1300 images\n",
            "\n",
            "Statistiques des dimensions:\n",
            "  Largeur  - Min:  256px, Max:  956px, Moyenne: 401.8px\n",
            "  Hauteur  - Min:  256px, Max: 1072px, Moyenne: 415.6px\n",
            "  Ratio L/H - Min: 0.49, Max: 1.91, Moyenne: 0.98\n",
            "\n",
            " Graphique sauvegardé dans: A:\\Mes documents\\CNN\\outputs\\figures\\eda\\02_distribution_dimensions.png\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "widths = []\n",
        "heights = []\n",
        "aspects = []\n",
        "\n",
        "for class_name in tqdm(CLASSES, desc=\"Analyse des dimensions\"):\n",
        "    class_path = RAW_DATA_PATH / class_name\n",
        "    \n",
        "    if class_path.exists():\n",
        "        images = (list(class_path.glob(\"*.jpg\")) + \n",
        "                 list(class_path.glob(\"*.jpeg\")) + \n",
        "                 list(class_path.glob(\"*.png\")))\n",
        "        \n",
        "        # Échantillonner max 100 images par classe pour l'analyse   \n",
        "        sample_images = random.sample(images, min(100, len(images)))\n",
        "        \n",
        "        for img_path in sample_images:\n",
        "            dims = get_image_dimensions(img_path)\n",
        "            if dims:\n",
        "                w, h = dims\n",
        "                widths.append(w)\n",
        "                heights.append(h)\n",
        "                aspects.append(w / h if h > 0 else 1.0)\n",
        "\n",
        "print()\n",
        "print(f\"Analyse effectuée sur {len(widths)} images\")\n",
        "print()\n",
        "print(\"Statistiques des dimensions:\")\n",
        "print(f\"  Largeur  - Min: {min(widths):4d}px, Max: {max(widths):4d}px, Moyenne: {np.mean(widths):.1f}px\")\n",
        "print(f\"  Hauteur  - Min: {min(heights):4d}px, Max: {max(heights):4d}px, Moyenne: {np.mean(heights):.1f}px\")\n",
        "print(f\"  Ratio L/H - Min: {min(aspects):.2f}, Max: {max(aspects):.2f}, Moyenne: {np.mean(aspects):.2f}\")\n",
        "print()\n",
        "\n",
        "# Créer le graphique des dimensions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Largeur\n",
        "axes[0].hist(widths, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(np.mean(widths), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {np.mean(widths):.0f}px')\n",
        "axes[0].set_xlabel('Largeur (pixels)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Nombre d\\'images', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Largeurs', fontsize=14, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Hauteur\n",
        "axes[1].hist(heights, bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "axes[1].axvline(np.mean(heights), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {np.mean(heights):.0f}px')\n",
        "axes[1].set_xlabel('Hauteur (pixels)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Nombre d\\'images', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(' Hauteurs', fontsize=14, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Ratio\n",
        "axes[2].hist(aspects, bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
        "axes[2].axvline(np.mean(aspects), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {np.mean(aspects):.2f}')\n",
        "axes[2].set_xlabel('Ratio Largeur/Hauteur', fontsize=12, fontweight='bold')\n",
        "axes[2].set_ylabel('Nombre d\\'images', fontsize=12, fontweight='bold')\n",
        "axes[2].set_title('Distribution des Ratios', fontsize=14, fontweight='bold')\n",
        "axes[2].legend()\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = EDA_FIGURES_DIR / '02_distribution_dimensions.png'\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Graphique sauvegardé dans: {save_path}\")\n",
        "plt.close()\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Analyse de la luminosité"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyse de la luminosité: 100%|██████████| 13/13 [00:04<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyse effectuée sur 1300 images\n",
            "\n",
            "Statistiques de luminosité:\n",
            "  Min     : 36.8\n",
            "  Max     : 240.3\n",
            "  Moyenne : 108.2\n",
            "  Médiane : 107.5\n",
            "  Écart-type: 29.6\n",
            "\n",
            " Graphique sauvegardé dans: A:\\Mes documents\\CNN\\outputs\\figures\\eda\\03_distribution_luminosite.png\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "brightnesses = []\n",
        "\n",
        "for class_name in tqdm(CLASSES, desc=\"Analyse de la luminosité\"):\n",
        "    class_path = RAW_DATA_PATH / class_name\n",
        "    \n",
        "    if class_path.exists():\n",
        "        images = (list(class_path.glob(\"*.jpg\")) + \n",
        "                 list(class_path.glob(\"*.jpeg\")) + \n",
        "                 list(class_path.glob(\"*.png\")))\n",
        "        \n",
        "        sample_images = random.sample(images, min(100, len(images)))\n",
        "        \n",
        "        for img_path in sample_images:\n",
        "            brightness = get_image_brightness(img_path)\n",
        "            if brightness is not None:\n",
        "                brightnesses.append(brightness)\n",
        "\n",
        "print()\n",
        "print(f\"Analyse effectuée sur {len(brightnesses)} images\")\n",
        "print()\n",
        "print(\"Statistiques de luminosité:\")\n",
        "print(f\"  Min     : {min(brightnesses):.1f}\")\n",
        "print(f\"  Max     : {max(brightnesses):.1f}\")\n",
        "print(f\"  Moyenne : {np.mean(brightnesses):.1f}\")\n",
        "print(f\"  Médiane : {np.median(brightnesses):.1f}\")\n",
        "print(f\"  Écart-type: {np.std(brightnesses):.1f}\")\n",
        "print()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(brightnesses, bins=50, color='gold', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(np.mean(brightnesses), color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Moyenne: {np.mean(brightnesses):.1f}')\n",
        "plt.axvline(np.median(brightnesses), color='blue', linestyle='--', linewidth=2, \n",
        "            label=f'Médiane: {np.median(brightnesses):.1f}')\n",
        "plt.xlabel('Luminosité moyenne [0-255]', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Nombre d\\'images', fontsize=12, fontweight='bold')\n",
        "plt.title('Luminosité des Images', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = EDA_FIGURES_DIR / '03_distribution_luminosite.png'\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Graphique sauvegardé dans: {save_path}\")\n",
        "plt.close()\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Visualisation d'échantillons aléatoires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Graphique sauvegardé dans: A:\\Mes documents\\CNN\\outputs\\figures\\eda\\04_echantillons_par_classe.png\n"
          ]
        }
      ],
      "source": [
        "\n",
        "fig, axes = plt.subplots(13, 5, figsize=(15, 35))\n",
        "fig.suptitle('Échantillons Aléatoires par Classe (5 images/classe)', \n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "for idx, class_name in enumerate(CLASSES):\n",
        "    class_path = RAW_DATA_PATH / class_name\n",
        "    \n",
        "    if class_path.exists():\n",
        "        images = (list(class_path.glob(\"*.jpg\")) + \n",
        "                 list(class_path.glob(\"*.jpeg\")) + \n",
        "                 list(class_path.glob(\"*.png\")))\n",
        "        \n",
        "        sample_images = random.sample(images, min(5, len(images)))\n",
        "        \n",
        "        for col, img_path in enumerate(sample_images):\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                axes[idx, col].imshow(img)\n",
        "                axes[idx, col].axis('off')\n",
        "                if col == 0:\n",
        "                    axes[idx, col].set_title(class_name, fontsize=10, loc='left')\n",
        "            except:\n",
        "                axes[idx, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = EDA_FIGURES_DIR / '04_echantillons_par_classe.png'\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Graphique sauvegardé dans: {save_path}\")\n",
        "plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SECTION 4 : EQUILIBRAGE STRATIFIÉ DU DATASET\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Objectif : Sélectionner 850 images par classe\n",
            "Stratégie : Stratified Random Sampling\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Objectif : Sélectionner {IMAGES_PER_CLASS} images par classe\")\n",
        "print(f\"Stratégie : {'Stratified Random Sampling' if STRATIFIED_SAMPLING else 'Random Sampling'}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. LA Fonction d'équilibrage "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stratified_sampling(images_list, n_samples, brightness_bins=4):\n",
        "   \n",
        "    if len(images_list) <= n_samples:\n",
        "        return images_list\n",
        "    \n",
        "    # Calculer la luminosité pour toutes les images\n",
        "    print(\"      Calcul des luminosités...\")\n",
        "    brightnesses_dict = {}\n",
        "    for img_path in tqdm(images_list, desc=\"      \", leave=False):\n",
        "        brightness = get_image_brightness(img_path)\n",
        "        if brightness is not None:\n",
        "            brightnesses_dict[img_path] = brightness\n",
        "    \n",
        "    # Créer des bins de luminosité\n",
        "    valid_images = list(brightnesses_dict.keys())\n",
        "    valid_brightnesses = list(brightnesses_dict.values())\n",
        "    \n",
        "    # Diviser en bins\n",
        "    bins = np.linspace(min(valid_brightnesses), max(valid_brightnesses), brightness_bins + 1)\n",
        "    bin_indices = np.digitize(valid_brightnesses, bins) - 1\n",
        "    \n",
        "    # Échantillonner proportionnellement dans chaque bin\n",
        "    selected_images = []\n",
        "    samples_per_bin = n_samples // brightness_bins\n",
        "    remaining = n_samples % brightness_bins\n",
        "    \n",
        "    for bin_idx in range(brightness_bins):\n",
        "        bin_images = [img for img, b_idx in zip(valid_images, bin_indices) if b_idx == bin_idx]\n",
        "        \n",
        "        n_to_sample = samples_per_bin + (1 if bin_idx < remaining else 0)\n",
        "        n_to_sample = min(n_to_sample, len(bin_images))\n",
        "        \n",
        "        selected_images.extend(random.sample(bin_images, n_to_sample))\n",
        "    \n",
        "    # Si on n'a pas assez,on le  compléter aléatoirement\n",
        "    if len(selected_images) < n_samples:\n",
        "        remaining_images = [img for img in valid_images if img not in selected_images]\n",
        "        additional = random.sample(remaining_images, n_samples - len(selected_images))\n",
        "        selected_images.extend(additional)\n",
        "    \n",
        "    return selected_images[:n_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Équilibrage et copie des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traitement de la classe: abraham_grampa_simpson\n",
            "   Images disponibles: 913\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: bart_simpson\n",
            "   Images disponibles: 1342\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: charles_montgomery_burns\n",
            "   Images disponibles: 1193\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: chief_wiggum\n",
            "   Images disponibles: 986\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: homer_simpson\n",
            "   Images disponibles: 2246\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: krusty_the_clown\n",
            "   Images disponibles: 1206\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: lisa_simpson\n",
            "   Images disponibles: 1354\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: marge_simpson\n",
            "   Images disponibles: 1291\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: milhouse_van_houten\n",
            "   Images disponibles: 1079\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: moe_szyslak\n",
            "   Images disponibles: 1452\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: ned_flanders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images disponibles: 1454\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: principal_skinner\n",
            "   Images disponibles: 1194\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n",
            "Traitement de la classe: sideshow_bob\n",
            "   Images disponibles: 877\n",
            "      Calcul des luminosités...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Images sélectionnées: 850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Terminé\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "\n",
        "# Création du dossier pour le dataset équilibré\n",
        "BALANCED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "balanced_counts = {}\n",
        "\n",
        "for class_name in CLASSES:\n",
        "    print(f\"Traitement de la classe: {class_name}\")\n",
        "    \n",
        "    # Chemin source et destination\n",
        "    source_class_path = RAW_DATA_PATH / class_name\n",
        "    dest_class_path = BALANCED_DATA_PATH / class_name\n",
        "    dest_class_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    if source_class_path.exists():\n",
        "        # Récupération de toutes les images \n",
        "        all_images = (list(source_class_path.glob(\"*.jpg\")) + \n",
        "                     list(source_class_path.glob(\"*.jpeg\")) + \n",
        "                     list(source_class_path.glob(\"*.png\")))\n",
        "        \n",
        "        print(f\"   Images disponibles: {len(all_images)}\")\n",
        "        \n",
        "        # Sélection des images \n",
        "        if STRATIFIED_SAMPLING and len(all_images) > IMAGES_PER_CLASS:\n",
        "            selected_images = stratified_sampling(all_images, IMAGES_PER_CLASS)\n",
        "        else:\n",
        "            # Random sampling simple\n",
        "            n_to_sample = min(IMAGES_PER_CLASS, len(all_images))\n",
        "            selected_images = random.sample(all_images, n_to_sample)\n",
        "        \n",
        "        print(f\"   Images sélectionnées: {len(selected_images)}\")\n",
        "        \n",
        "        # Copie des images sélectionnées\n",
        "        for img_path in tqdm(selected_images, desc=\"      Copie\", leave=False):\n",
        "            dest_path = dest_class_path / img_path.name\n",
        "            if not dest_path.exists():\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "        \n",
        "        balanced_counts[class_name] = len(selected_images)\n",
        "        print(f\"    Terminé\")\n",
        "    else:\n",
        "        print(f\"     Dossier source introuvable\")\n",
        "        balanced_counts[class_name] = 0\n",
        "    \n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Vérification du dataset équilibré"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'images par classe:\n",
            "\n",
            "  abraham_grampa_simpson              :  850 images\n",
            "  bart_simpson                        :  850 images\n",
            "  charles_montgomery_burns            :  850 images\n",
            "  chief_wiggum                        :  850 images\n",
            "  homer_simpson                       :  850 images\n",
            "  krusty_the_clown                    :  850 images\n",
            "  lisa_simpson                        :  850 images\n",
            "  marge_simpson                       :  850 images\n",
            "  milhouse_van_houten                 :  850 images\n",
            "  moe_szyslak                         :  850 images\n",
            "  ned_flanders                        :  850 images\n",
            "  principal_skinner                   :  850 images\n",
            "  sideshow_bob                        :  850 images\n",
            "------------------------------------------------------------\n",
            "  TOTAL                               : 11050 images\n",
            "\n",
            "Split train/validation (80/19):\n",
            "  Train      :  8840 images (680 par classe)\n",
            "  Validation :  2210 images (170 par classe)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Nombre d'images par classe:\")\n",
        "print()\n",
        "\n",
        "total_balanced = 0\n",
        "for class_name, count in balanced_counts.items():\n",
        "    print(f\"  {class_name:35s} : {count:4d} images\")\n",
        "    total_balanced += count\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"  {'TOTAL':35s} : {total_balanced:4d} images\")\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "# Calculer le nombre d'images pour train et validation\n",
        "n_train = int(total_balanced * TRAIN_VAL_SPLIT)\n",
        "n_val = total_balanced - n_train\n",
        "\n",
        "print(f\"Split train/validation ({int(TRAIN_VAL_SPLIT*100)}/{int((1-TRAIN_VAL_SPLIT)*100)}):\")\n",
        "print(f\"  Train      : {n_train:5d} images ({int(n_train/N_CLASSES)} par classe)\")\n",
        "print(f\"  Validation : {n_val:5d} images ({int(n_val/N_CLASSES)} par classe)\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Visualisation du dataset équilibré"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Graphique sauvegardé dans : A:\\Mes documents\\CNN\\outputs\\figures\\eda\\05_distribution_equilibree.png\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "classes_names = list(balanced_counts.keys())\n",
        "classes_counts = list(balanced_counts.values())\n",
        "\n",
        "bars = plt.bar(range(len(classes_names)), classes_counts, \n",
        "               color='seagreen', alpha=0.8, edgecolor='darkgreen', linewidth=1.5)\n",
        "\n",
        "# Ajouter les valeurs\n",
        "for bar, value in zip(bars, classes_counts):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
        "            f'{value}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Ligne de cible\n",
        "plt.axhline(y=IMAGES_PER_CLASS, color='red', linestyle='--', linewidth=2, \n",
        "            label=f'Cible: {IMAGES_PER_CLASS} images', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Classes (Personnages)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Nombre d\\'images', fontsize=14, fontweight='bold')\n",
        "plt.title('Distribution des Images par Classe (celui du Dataset Équilibré)', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xticks(range(len(classes_names)), classes_names, rotation=45, ha='right', fontsize=10)\n",
        "plt.ylim([0, IMAGES_PER_CLASS + 50])\n",
        "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "plt.legend(fontsize=12)\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = EDA_FIGURES_DIR / '05_distribution_equilibree.png'\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Graphique sauvegardé dans : {save_path}\")\n",
        "plt.close()\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5 - Sauvegarde "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Rapport d'équilibrage sauvegardé dans : A:\\Mes documents\\CNN\\outputs\\reports\\balanced_data_report.csv\n",
            "\n",
            "Aperçu du rapport:\n",
            "                  Classe  Images_Brutes  Images_Equilibrees  Difference\n",
            "  abraham_grampa_simpson            913                 850         -63\n",
            "            bart_simpson           1342                 850        -492\n",
            "charles_montgomery_burns           1193                 850        -343\n",
            "            chief_wiggum            986                 850        -136\n",
            "           homer_simpson           2246                 850       -1396\n",
            "        krusty_the_clown           1206                 850        -356\n",
            "            lisa_simpson           1354                 850        -504\n",
            "           marge_simpson           1291                 850        -441\n",
            "     milhouse_van_houten           1079                 850        -229\n",
            "             moe_szyslak           1452                 850        -602\n",
            "            ned_flanders           1454                 850        -604\n",
            "       principal_skinner           1194                 850        -344\n",
            "            sideshow_bob            877                 850         -27\n",
            "                   TOTAL          16587               11050       -5537\n",
            "\n"
          ]
        }
      ],
      "source": [
        "balanced_report = pd.DataFrame([\n",
        "    {\n",
        "        'Classe': classe, \n",
        "        'Images_Brutes': image_counts[classe],\n",
        "        'Images_Equilibrees': balanced_counts[classe],\n",
        "        'Difference': balanced_counts[classe] - image_counts[classe]\n",
        "    }\n",
        "    for classe in CLASSES\n",
        "])\n",
        "\n",
        "balanced_report.loc[len(balanced_report)] = [\n",
        "    'TOTAL',\n",
        "    sum(image_counts.values()),\n",
        "    sum(balanced_counts.values()),\n",
        "    sum(balanced_counts.values()) - sum(image_counts.values())\n",
        "]\n",
        "\n",
        "report_path = REPORTS_DIR / 'balanced_data_report.csv'\n",
        "balanced_report.to_csv(report_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\" Rapport d'équilibrage sauvegardé dans : {report_path}\")\n",
        "print()\n",
        "print(\"Aperçu du rapport:\")\n",
        "print(balanced_report.to_string(index=False))\n",
        "print()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
